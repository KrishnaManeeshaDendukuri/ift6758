{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c968ff0-ccd9-4cc6-90f9-2ade7c7b1b1a",
   "metadata": {},
   "source": [
    "# Data from comet_ml import ExperimentPreparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44c277b-8ef7-4988-94a9-d4240ed81ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import sys\n",
    "sys.path.append('../ift6758/data/')\n",
    "from question_2_m2 import *\n",
    "from question_4_m2 import get_new_features, get_angle_change\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dca1dfd-3a04-4bf8-b7a2-aa0e977eec43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = tidy_df_loop([2016, 2017, 2018, 2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f44e4bf-28cc-46ad-b6b0-1cd6db32ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('tidy_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3863f6d2-1738-406a-81a5-b9f6716b451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tidy_df2.csv')\n",
    "df = df.drop(columns = 'Unnamed: 0')\n",
    "df = df[df['season_type'] == 'R']\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38102e20-1e84-4efe-8310-b3c4a2a5c354",
   "metadata": {},
   "source": [
    "Add features from q2 and q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61f3261-aaa2-4830-8aab-b6f587fb02b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_angle = []\n",
    "for i in range(0,df.shape[0]):\n",
    "\n",
    "    if df.attacking_team_side[i] == \"right\":\n",
    "        if df.y_coordinates[i] == 0:\n",
    "            list_angle.append(0)\n",
    "        elif df.y_coordinates[i] > 0:\n",
    "            list_angle.append(np.arcsin(df.y_coordinates[i]/df.distance_from_net[i])*-180/math.pi)\n",
    "        else:\n",
    "            list_angle.append(np.arcsin(df.y_coordinates[i]/df.distance_from_net[i])*-180/math.pi)\n",
    "            \n",
    "    elif df.attacking_team_side[i] == \"left\":\n",
    "        if df.y_coordinates[i] == 0:\n",
    "            list_angle.append(0)\n",
    "        elif df.y_coordinates[i] > 0:\n",
    "            list_angle.append(np.arcsin(df.y_coordinates[i]/df.distance_from_net[i])*180/math.pi)\n",
    "        else:\n",
    "            list_angle.append(np.arcsin(df.y_coordinates[i]/df.distance_from_net[i])*180/math.pi)\n",
    "df['angle_from_net'] = list_angle\n",
    "\n",
    "df = get_new_features(df)\n",
    "df = get_angle_change(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9c014-f551-451a-8fdf-9f048f1049a2",
   "metadata": {},
   "source": [
    "Add 'defending_team' feature, one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbd7609-2ff7-4ab0-9618-44a248a898f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['defending_team'] = np.where(df['attacking_team'] == df['home_team'], df['away_team'], df['home_team']) + \"_def\"\n",
    "df = df.join(pd.get_dummies(df[['defending_team', 'attacking_team']]))\n",
    "\n",
    "#cols_to_drop = [s for s in list(df.columns) if 'goalie' in s]\n",
    "#df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2109c-fdb9-4fe3-b69d-dda74a2e99d2",
   "metadata": {},
   "source": [
    "bit of clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0ac188-6189-49d6-bc6f-fe30b32c6445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keep only numeric columns\n",
    "df = df.select_dtypes(include=np.number)\n",
    "\n",
    "# drop some irrelevant columns\n",
    "cols_to_drop = ['game_id', 'event_id', 'shot_ind', 'x_coordinates', 'y_coordinates', \n",
    "                'previous_event_x_coordinates', 'previous_event_y_coordinates', 'previous_event_period', \n",
    "                'home_players', 'away_players', 'previous_event_game_seconds', 'previous_event_game_seconds']\n",
    "df = df.drop(columns = cols_to_drop)\n",
    "\n",
    "# impute NAs\n",
    "df['distance_from_net'] = df['distance_from_net'].fillna(df['distance_from_net'].median())\n",
    "df['distance_from_last_event'] = df['distance_from_last_event'].fillna(df['distance_from_last_event'].median())\n",
    "df['speed'] = df['speed'].fillna(df['speed'].median())\n",
    "df['speed'] = df['speed'].replace([np.inf, -np.inf], df['speed'].median())\n",
    "df['angle_from_net'] = df['angle_from_net'].fillna(df['angle_from_net'].median())\n",
    "df['change_in_angle'] = df['change_in_angle'].fillna(df['change_in_angle'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270731f-85ae-4d0c-9c2c-c84b0806b88a",
   "metadata": {},
   "source": [
    "Create train and validation sets, convert df to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47afcc9b-d5ae-4664-8de3-3122a30206bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['season'] != 20182019]\n",
    "df_valid = df[df['season'] == 20182019]\n",
    "\n",
    "X_train = df_train.drop(columns = ['season', 'goal_ind'])\n",
    "y_train = df_train['goal_ind']\n",
    "\n",
    "X_valid = df_valid.drop(columns = ['season', 'goal_ind'])\n",
    "y_valid = df_valid['goal_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffdf601e-8214-4c72-aa3b-9d642489d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.to_numpy()).float()\n",
    "X_valid = torch.tensor(X_valid.to_numpy()).float()\n",
    "\n",
    "y_train = torch.tensor(y_train.to_numpy())\n",
    "y_valid = torch.tensor(y_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763b006-906f-4d16-aa18-3c97ca5ef20a",
   "metadata": {},
   "source": [
    "## 2 layer Neural Net Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbb9fc-7670-47d3-ad45-d2635ca9412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "jj=1\n",
    "for hidden_dim in [8, 16, 32]:\n",
    "    for lr in [0.0002, 0.001, 0.005]:\n",
    "\n",
    "        # model class\n",
    "        class binary_classifier(nn.Module):\n",
    "\n",
    "            def __init__(self):\n",
    "                super(binary_classifier,self).__init__()\n",
    "                self.layer1 = nn.Linear(X_train.shape[1], hidden_dim)\n",
    "                self.layer2 = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "            def forward(self,x):\n",
    "                x = F.relu(self.layer1(x))\n",
    "                x = self.layer2(x)\n",
    "                return x\n",
    "\n",
    "            #This function takes an input and predicts the class, (0 or 1)        \n",
    "            def predict_class(self,x):\n",
    "                #Apply softmax to output. \n",
    "                pred = F.softmax(self.forward(x), dim=1)\n",
    "                ans = []\n",
    "                #Pick the class with maximum weight\n",
    "                for t in pred:\n",
    "                    if t[0]>t[1]:\n",
    "                        ans.append(0)\n",
    "                    else:\n",
    "                        ans.append(1)\n",
    "                return torch.tensor(ans)\n",
    "\n",
    "            def predict_probs(self,x):\n",
    "                #Apply softmax to output. \n",
    "                pred = F.softmax(self.forward(x), dim=1)\n",
    "                return pred\n",
    "            \n",
    "        # initialise model\n",
    "        model = binary_classifier()\n",
    "        loss_computation = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # trainning\n",
    "        epochs = 2000\n",
    "        \n",
    "        # Store metrics\n",
    "        epochs_list = []\n",
    "        losses = []\n",
    "        losses_valid = []\n",
    "        train_rocs = []\n",
    "        valid_rocs = []\n",
    "\n",
    "        for i in range(epochs):\n",
    "            y_pred = model.forward(X_train)\n",
    "            loss = loss_computation(y_pred,y_train)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 100 == 0:\n",
    "                preds = model.predict_probs(X_train)\n",
    "                goal_index = np.argmin(preds.sum(dim=0).detach().numpy())\n",
    "                fpr, tpr, _ = roc_curve(np.array(y_train), preds[:,goal_index].detach().numpy())\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                preds_valid = model.predict_probs(X_valid)\n",
    "                goal_index_valid = np.argmin(preds_valid.sum(dim=0).detach().numpy())\n",
    "                fpr_valid, tpr_valid, _ = roc_curve(np.array(y_valid), preds_valid[:,goal_index_valid].detach().numpy())\n",
    "                roc_auc_valid = auc(fpr_valid, tpr_valid)\n",
    "\n",
    "                y_pred_valid = model.forward(X_valid)\n",
    "                loss_valid = loss_computation(y_pred_valid, y_valid)\n",
    "\n",
    "                epochs_list.append(i+1)\n",
    "                losses.append(loss.item())\n",
    "                losses_valid.append(loss_valid.item())\n",
    "                train_rocs.append(roc_auc)\n",
    "                valid_rocs.append(roc_auc_valid)\n",
    "            \n",
    "        # plot metrics\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 4))\n",
    "        fig.suptitle(f'hidden dim = {hidden_dim}, learning rate = {lr}')\n",
    "        axs[0].plot(epochs_list, losses)\n",
    "        axs[0].plot(epochs_list, losses_valid)\n",
    "        axs[0].set_title(f'Cross Entropy Loss, best valid score = {min(losses_valid)}', fontsize=11)\n",
    "        axs[0].legend(labels = ['train', 'valid'])\n",
    "        axs[0].set_ylabel('Loss')\n",
    "        axs[0].set_xlabel('Training Epoch')\n",
    "        axs[0].set_ylim([0, 1.05*max([max(losses), max(losses_valid)])])\n",
    "        \n",
    "        axs[1].plot(epochs_list, train_rocs)\n",
    "        axs[1].plot(epochs_list, valid_rocs)\n",
    "        axs[1].set_title(f'ROC AUC, best valid score = {max(valid_rocs)}', fontsize=11)\n",
    "        axs[1].legend(labels = ['train', 'valid'])\n",
    "        axs[1].set_ylabel('AUC')\n",
    "        axs[1].set_xlabel('Training Epoch')\n",
    "        axs[1].set_ylim([ 0.95*min([min(train_rocs), min(valid_rocs)]), 1.05*max([max(train_rocs), max(valid_rocs)])])\n",
    "        print(jj)\n",
    "        jj += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae0438-b390-4540-9bba-12cc8954acef",
   "metadata": {},
   "source": [
    "## 3 layer Neural Net softmax classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c596eb-a404-46e0-9cc1-58fa37e16a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj=1\n",
    "for hidden_dims in [[32,8], [16,16]]:\n",
    "    for lr in [0.0002, 0.001, 0.005]:\n",
    "\n",
    "        # model class\n",
    "        class binary_classifier(nn.Module):\n",
    "\n",
    "            def __init__(self):\n",
    "                super(binary_classifier,self).__init__()\n",
    "                self.layer1 = nn.Linear(X_train.shape[1], hidden_dims[0])\n",
    "                self.layer2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "                self.layer3 = nn.Linear(hidden_dims[1], 2)\n",
    "\n",
    "            def forward(self,x):\n",
    "                x = F.relu(self.layer1(x))\n",
    "                x = F.relu(self.layer2(x))\n",
    "                x = self.layer3(x)\n",
    "                return x\n",
    "\n",
    "            #This function takes an input and predicts the class, (0 or 1)        \n",
    "            def predict_class(self,x):\n",
    "                #Apply softmax to output. \n",
    "                pred = F.softmax(self.forward(x), dim=1)\n",
    "                ans = []\n",
    "                #Pick the class with maximum weight\n",
    "                for t in pred:\n",
    "                    if t[0]>t[1]:\n",
    "                        ans.append(0)\n",
    "                    else:\n",
    "                        ans.append(1)\n",
    "                return torch.tensor(ans)\n",
    "\n",
    "            def predict_probs(self,x):\n",
    "                #Apply softmax to output. \n",
    "                pred = F.softmax(self.forward(x), dim=1)\n",
    "                return pred\n",
    "            \n",
    "        # initialise model\n",
    "        model = binary_classifier()\n",
    "        loss_computation = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # trainning\n",
    "        epochs = 2000\n",
    "        \n",
    "        # Store metrics\n",
    "        epochs_list = []\n",
    "        losses = []\n",
    "        losses_valid = []\n",
    "        train_rocs = []\n",
    "        valid_rocs = []\n",
    "\n",
    "        for i in range(epochs):\n",
    "            y_pred = model.forward(X_train)\n",
    "            loss = loss_computation(y_pred,y_train)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 100 == 0:\n",
    "                preds = model.predict_probs(X_train)\n",
    "                goal_index = np.argmin(preds.sum(dim=0).detach().numpy())\n",
    "                fpr, tpr, _ = roc_curve(np.array(y_train), preds[:,goal_index].detach().numpy())\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                preds_valid = model.predict_probs(X_valid)\n",
    "                goal_index_valid = np.argmin(preds_valid.sum(dim=0).detach().numpy())\n",
    "                fpr_valid, tpr_valid, _ = roc_curve(np.array(y_valid), preds_valid[:,goal_index_valid].detach().numpy())\n",
    "                roc_auc_valid = auc(fpr_valid, tpr_valid)\n",
    "\n",
    "                y_pred_valid = model.forward(X_valid)\n",
    "                loss_valid = loss_computation(y_pred_valid, y_valid)\n",
    "\n",
    "                epochs_list.append(i+1)\n",
    "                losses.append(loss.item())\n",
    "                losses_valid.append(loss_valid.item())\n",
    "                train_rocs.append(roc_auc)\n",
    "                valid_rocs.append(roc_auc_valid)\n",
    "            \n",
    "        # plot metrics\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 4))\n",
    "        fig.suptitle(f'hidden dim = {hidden_dim}, learning rate = {lr}')\n",
    "        axs[0].plot(epochs_list, losses)\n",
    "        axs[0].plot(epochs_list, losses_valid)\n",
    "        axs[0].set_title(f'Cross Entropy Loss, best valid score = {min(losses_valid)}', fontsize=11)\n",
    "        axs[0].legend(labels = ['train', 'valid'])\n",
    "        axs[0].set_ylabel('Loss')\n",
    "        axs[0].set_xlabel('Training Epoch')\n",
    "        axs[0].set_ylim([0, 1.05*max([max(losses), max(losses_valid)])])\n",
    "        \n",
    "        axs[1].plot(epochs_list, train_rocs)\n",
    "        axs[1].plot(epochs_list, valid_rocs)\n",
    "        axs[1].set_title(f'ROC AUC, best valid score = {max(valid_rocs)}', fontsize=11)\n",
    "        axs[1].legend(labels = ['train', 'valid'])\n",
    "        axs[1].set_ylabel('AUC')\n",
    "        axs[1].set_xlabel('Training Epoch')\n",
    "        axs[1].set_ylim([ 0.95*min([min(train_rocs), min(valid_rocs)]), 1.05*max([max(train_rocs), max(valid_rocs)])])\n",
    "        \n",
    "        print(jj)\n",
    "        jj += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c595ff-b2d0-4a33-91d2-6dd0bb8abed9",
   "metadata": {},
   "source": [
    "## Retrain final model with best hyperparams, log into comet, save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916f5fa-972d-45da-ac5d-2c9576c65ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
